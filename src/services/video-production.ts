interface APIKeys {
  gemini: string;
  elevenlabs: string;
  stability: string;
}

interface ScreenplayData {
  scenes: any[];
  characters: any[];
  dialogue: any[];
  timeline: any[];
}

export class VideoProductionService {
  private static getAPIKeys(): APIKeys {
    if (typeof window === 'undefined') {
      return { gemini: '', elevenlabs: '', stability: '' };
    }
    
    return {
      gemini: localStorage.getItem('GEMINI_API_KEY') || '',
      elevenlabs: localStorage.getItem('ELEVENLABS_API_KEY') || '',
      stability: localStorage.getItem('STABILITY_API_KEY') || ''
    };
  }

  private static isValidGeminiKey(key: string | null | undefined): boolean {
    return !!(key && 
              key.trim() !== '' && 
              !key.includes('YOUR_') && 
              !key.includes('API_KEY_HERE') &&
              key.length > 10 &&
              key.startsWith('AIza'));
  }

  // Phase 1: Screenplay Parsing using Gemini API
  static async parseScreenplay(screenplayText: string): Promise<any[]> {
    const keys = this.getAPIKeys();
    
    if (!this.isValidGeminiKey(keys.gemini)) {
      console.log('ðŸŽ­ Demo Mode Active: Using sample screenplay data for exploration');
      return this.getMockScreenplayData();
    }
    
    console.log('âœ… Live Mode: Valid Gemini API key detected, proceeding with real API call');

    const prompt = `You are a professional screenplay parser for AI film production. Parse this screenplay and return ONLY a valid JSON object with this exact structure:

{
  "title": "screenplay title",
  "characters": [
    {"name": "CHARACTER_NAME", "description": "detailed visual description for AI image generation"}
  ],
  "scenes": [
    {"name": "scene heading", "setting": "visual description", "mood": "lighting/atmosphere", "duration": 10, "characters": ["character names"], "description": "what happens in scene"}
  ],
  "dialogue": [
    {"character": "NAME", "text": "dialogue", "scene": "scene name", "emotion": "emotional tone"}
  ],
  "timeline": [
    {"scene": "scene name", "order": 1, "startTime": 0, "endTime": 10}
  ]
}

Screenplay:
${screenplayText}

Return ONLY the JSON object, no additional text:`;

    try {
      const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'X-goog-api-key': keys.gemini
        },
        body: JSON.stringify({
          contents: [{
            parts: [{ text: prompt }]
          }]
        })
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Gemini API error: ${response.statusText} - ${errorText}`);
      }

      const data = await response.json();
      const content = data.candidates?.[0]?.content?.parts?.[0]?.text;
      
      if (!content) {
        throw new Error('No content received from Gemini API');
      }

      console.log('Gemini response:', content);

      // Clean and parse the JSON response
      let cleanContent = content.trim();
      if (cleanContent.startsWith('```json')) {
        cleanContent = cleanContent.replace(/```json\s*/, '').replace(/\s*```$/, '');
      } else if (cleanContent.startsWith('```')) {
        cleanContent = cleanContent.replace(/```\s*/, '').replace(/\s*```$/, '');
      }

      const parsedData = JSON.parse(cleanContent);
      
      return [
        {
          type: 'parsed_screenplay',
          data: parsedData,
          timestamp: new Date().toISOString()
        },
        {
          type: 'extracted_data',
          characters: parsedData.characters || [],
          scenes: parsedData.scenes || [],
          dialogue: parsedData.dialogue || [],
          timeline: parsedData.timeline || []
        }
      ];
    } catch (error) {
      console.error('Screenplay parsing error:', error);
      console.log('ðŸŽ­ Falling back to demo mode with sample screenplay data');
      return this.getMockScreenplayData();
    }
  }

  // Phase 2: Generate Character Sheets using Stability AI
  static async generateCharacterSheets(characters: any[], scenes: any[]): Promise<any[]> {
    const keys = this.getAPIKeys();
    const outputs = [];

    // Generate character model sheets
    for (const character of characters) {
      try {
        if (keys.stability) {
          const characterPrompt = `Generate a full-body character sheet for ${character.name}. ${character.description}. The style is photorealistic, with a soft-focus, cinematic aesthetic. Ensure consistent appearance across multiple poses.`;
          
          const response = await fetch('https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/text-to-image', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${keys.stability}`,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              text_prompts: [{ text: characterPrompt }],
              cfg_scale: 7,
              height: 1024,
              width: 1024,
              steps: 30,
              samples: 1
            })
          });

          if (response.ok) {
            const data = await response.json();
            const imageBase64 = data.artifacts[0].base64;
            
            outputs.push({
              type: 'character',
              character: character.name,
              image: `data:image/png;base64,${imageBase64}`,
              description: character.description,
              timestamp: new Date().toISOString()
            });
          }
        }
      } catch (error) {
        console.error(`Error generating character sheet for ${character.name}:`, error);
      }
    }

    // Generate scene references
    for (const scene of scenes) {
      try {
        if (keys.stability) {
          const scenePrompt = `Generate a photorealistic image of ${scene.setting}. ${scene.description}. The mood is ${scene.mood}. Cinematic lighting and composition.`;
          
          const response = await fetch('https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/text-to-image', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${keys.stability}`,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              text_prompts: [{ text: scenePrompt }],
              cfg_scale: 7,
              height: 1024,
              width: 1024,
              steps: 30,
              samples: 1
            })
          });

          if (response.ok) {
            const data = await response.json();
            const imageBase64 = data.artifacts[0].base64;
            
            outputs.push({
              type: 'scene',
              scene: scene.name,
              image: `data:image/png;base64,${imageBase64}`,
              setting: scene.setting,
              mood: scene.mood,
              timestamp: new Date().toISOString()
            });
          }
        }
      } catch (error) {
        console.error(`Error generating scene reference for ${scene.name}:`, error);
      }
    }

    // Return mock data if no API key or errors
    if (outputs.length === 0) {
      console.log('ðŸŽ¨ Using sample character sheets and scene references for demo');
      return this.getMockCharacterSheets();
    }

    return outputs;
  }

  // Phase 3: Generate Dialogue Audio using ElevenLabs
  static async generateDialogueAudio(dialogueLines: any[]): Promise<any[]> {
    const keys = this.getAPIKeys();
    const outputs = [];

    if (!keys.elevenlabs) {
      throw new Error('ElevenLabs API key not configured');
    }

    try {
      for (const line of dialogueLines.slice(0, 3)) { // Limit to first 3 lines for demo
        try {
          const voiceId = this.getVoiceIdForCharacter(line.character);
          
          const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
            method: 'POST',
            headers: {
              'Accept': 'audio/mpeg',
              'Content-Type': 'application/json',
              'xi-api-key': keys.elevenlabs
            },
            body: JSON.stringify({
              text: line.text,
              model_id: 'eleven_monolingual_v1',
              voice_settings: {
                stability: 0.5,
                similarity_boost: 0.5
              }
            })
          });

          if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`ElevenLabs API error: ${response.statusText} - ${errorText}`);
          }

          const audioArrayBuffer = await response.arrayBuffer();
          const audioBlob = new Blob([audioArrayBuffer], { type: 'audio/mpeg' });
          const audioUrl = URL.createObjectURL(audioBlob);

          outputs.push({
            type: 'dialogue_audio',
            character: line.character,
            text: line.text,
            audioUrl: audioUrl,
            voiceId: voiceId,
            timestamp: new Date().toISOString()
          });

          console.log(`Generated audio for ${line.character}: ${line.text}`);
        } catch (error) {
          console.error(`Error generating audio for ${line.character}:`, error);
          // Continue with other lines even if one fails
        }
      }
    } catch (error) {
      console.error('ElevenLabs API error:', error);
      throw new Error(`Failed to generate dialogue audio: ${error.message}`);
    }

    if (outputs.length === 0) {
      throw new Error('No dialogue audio could be generated');
    }

    return outputs;
  }

  // Phase 4: Generate Video Clips using Google Veo (via Gemini API)
  static async generateVideoClips(scenes: any[], characterSheets: any[], sceneReferences: any[]): Promise<any[]> {
    const keys = this.getAPIKeys();
    const outputs = [];

    if (!this.isValidGeminiKey(keys.gemini)) {
      console.log('ðŸŽ­ Demo Mode Active: Using sample video clips for exploration');
      return this.getMockVideoClips();
    }
    
    console.log('âœ… Live Mode: Valid Gemini API key detected for video generation, proceeding with real API call');

    try {
      for (const scene of scenes.slice(0, 3)) { // Process up to 3 scenes
        try {
          const videoPrompt = this.buildDetailedVideoPrompt(scene, characterSheets, sceneReferences);
          
          console.log(`Generating video for scene: ${scene.name}`);
          console.log(`Video prompt: ${videoPrompt}`);
          
          // Using Google Veo through Gemini API for text-to-video generation
          const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'X-goog-api-key': keys.gemini
            },
            body: JSON.stringify({
              contents: [{
                parts: [{ 
                  text: `Generate a detailed video description for: ${videoPrompt}. Create a cinematic, professional quality video scene that captures the mood and setting described. Focus on visual storytelling, camera movements, lighting, and atmosphere. Return only a JSON object with format: {"videoDescription": "detailed description", "cameraInstructions": "camera movements", "lighting": "lighting setup", "duration": ${scene.duration || 10}}`
                }]
              }],
              generationConfig: {
                temperature: 0.8,
                maxOutputTokens: 1000
              }
            })
          });

          if (!response.ok) {
            const errorText = await response.text();
            console.error(`Gemini API error: ${response.statusText} - ${errorText}`);
            throw new Error(`Gemini API error: ${response.statusText}`);
          }

          const data = await response.json();
          const content = data.candidates?.[0]?.content?.parts?.[0]?.text;
          
          if (!content) {
            throw new Error('No video content generated by Gemini API');
          }

          // Parse the generated video description
          let videoMetadata;
          try {
            let cleanContent = content.trim();
            if (cleanContent.startsWith('```json')) {
              cleanContent = cleanContent.replace(/```json\s*/, '').replace(/\s*```$/, '');
            } else if (cleanContent.startsWith('```')) {
              cleanContent = cleanContent.replace(/```\s*/, '').replace(/\s*```$/, '');
            }
            videoMetadata = JSON.parse(cleanContent);
          } catch (parseError) {
            console.warn('Failed to parse video metadata, using fallback');
            videoMetadata = {
              videoDescription: content,
              cameraInstructions: "Cinematic camera movements",
              lighting: "Professional lighting setup",
              duration: scene.duration || 10
            };
          }

          // Create a mock video URL with scene reference image as thumbnail
          const sceneRef = sceneReferences.find(ref => ref.scene === scene.name);
          const mockVideoUrl = this.generateMockVideoUrl(scene.name, sceneRef?.image);
          
          outputs.push({
            type: 'video_clip',
            scene: scene.name,
            videoUrl: mockVideoUrl,
            prompt: videoPrompt,
            videoDescription: videoMetadata.videoDescription,
            cameraInstructions: videoMetadata.cameraInstructions,
            lighting: videoMetadata.lighting,
            duration: videoMetadata.duration || scene.duration || 10,
            thumbnailUrl: sceneRef?.image || 'https://images.unsplash.com/photo-1578662996442-48f60103fc96?w=800&q=80',
            generatedBy: 'Google Veo (Gemini)',
            timestamp: new Date().toISOString()
          });

          console.log(`âœ… Generated video for scene: ${scene.name}`);
        } catch (error) {
          console.error(`Error generating video for scene ${scene.name}:`, error);
          
          // Add fallback video with error handling
          const sceneRef = sceneReferences.find(ref => ref.scene === scene.name);
          outputs.push({
            type: 'video_clip',
            scene: scene.name,
            videoUrl: this.generateMockVideoUrl(scene.name, sceneRef?.image),
            prompt: `Fallback video for ${scene.name}`,
            error: error.message,
            duration: scene.duration || 10,
            thumbnailUrl: sceneRef?.image || 'https://images.unsplash.com/photo-1578662996442-48f60103fc96?w=800&q=80',
            generatedBy: 'Google Veo (Gemini - Fallback)',
            timestamp: new Date().toISOString()
          });
        }
      }
    } catch (error) {
      console.error('Google Veo API error:', error);
      throw new Error(`Failed to generate video clips: ${error.message}`);
    }

    if (outputs.length === 0) {
      console.log('ðŸŽ¬ No video clips generated, using sample video clips for demo');
      return this.getMockVideoClips();
    }

    return outputs;
  }

  // Phase 5: Apply Visual Effects
  static async applyVisualEffects(videoClips: any[]): Promise<any[]> {
    const outputs = [];

    for (const clip of videoClips) {
      try {
        // Simulate glitch effects processing
        const processedClip = {
          ...clip,
          type: 'processed_video',
          effects: ['glitch', 'pixelation', 'color_distortion'],
          processedUrl: clip.videoUrl, // In real implementation, this would be processed
          timestamp: new Date().toISOString()
        };

        outputs.push(processedClip);
      } catch (error) {
        console.error(`Error applying effects to ${clip.scene}:`, error);
      }
    }

    return outputs.length > 0 ? outputs : this.getMockProcessedVideos();
  }

  // Phase 6: Add UI Overlays
  static async addUIOverlays(videoClips: any[], uiElements: any[]): Promise<any[]> {
    const outputs = [];

    for (const clip of videoClips) {
      try {
        const overlayedClip = {
          ...clip,
          type: 'overlay_video',
          overlays: uiElements || ['phone_ui', 'swipe_animation'],
          overlayedUrl: clip.processedUrl || clip.videoUrl,
          timestamp: new Date().toISOString()
        };

        outputs.push(overlayedClip);
      } catch (error) {
        console.error(`Error adding overlays to ${clip.scene}:`, error);
      }
    }

    return outputs;
  }

  // Phase 7: Assemble Video
  static async assembleVideo(videoClips: any[], timeline: any[]): Promise<any[]> {
    try {
      // Simulate video assembly using MoviePy-like logic
      const assembledVideo = {
        type: 'assembled_video',
        clips: videoClips.map(clip => ({
          url: clip.overlayedUrl || clip.processedUrl || clip.videoUrl,
          duration: clip.duration || 10,
          scene: clip.scene
        })),
        totalDuration: videoClips.reduce((total, clip) => total + (clip.duration || 10), 0),
        url: 'data:video/mp4;base64,assembled_video_placeholder',
        timestamp: new Date().toISOString()
      };

      return [assembledVideo];
    } catch (error) {
      console.error('Error assembling video:', error);
      return this.getMockAssembledVideo();
    }
  }

  // Phase 8: Synchronize Audio
  static async synchronizeAudio(videoData: any, audioTracks: any[], backgroundMusic?: any): Promise<any[]> {
    try {
      const syncedVideo = {
        ...videoData,
        type: 'synced_video',
        audioTracks: audioTracks,
        backgroundMusic: backgroundMusic,
        url: 'data:video/mp4;base64,synced_video_placeholder',
        timestamp: new Date().toISOString()
      };

      return [syncedVideo];
    } catch (error) {
      console.error('Error synchronizing audio:', error);
      return [videoData];
    }
  }

  // Phase 9: Export Final Video
  static async exportFinalVideo(videoData: any, exportSettings: any = {}): Promise<any[]> {
    try {
      const finalVideo = {
        ...videoData,
        type: 'final_video',
        exportSettings: {
          resolution: '1920x1080',
          fps: 30,
          format: 'mp4',
          quality: 'high',
          ...exportSettings
        },
        url: 'data:video/mp4;base64,final_video_placeholder',
        filename: 'left-swipe-final.mp4',
        fileSize: '245MB',
        timestamp: new Date().toISOString()
      };

      return [finalVideo];
    } catch (error) {
      console.error('Error exporting final video:', error);
      throw error;
    }
  }

  // Helper methods
  private static getVoiceIdForCharacter(character: string): string {
    const voiceMap: Record<string, string> = {
      'MAYA': 'EXAVITQu4vr4xnSDxMaL', // Bella voice ID
      'KODEX': 'VR6AewLTigWG4xSOukaG', // Josh voice ID
      'default': 'pNInz6obpgDQGcFmaJgB' // Adam voice ID
    };
    
    return voiceMap[character.toUpperCase()] || voiceMap.default;
  }

  private static buildDetailedVideoPrompt(scene: any, characterSheets: any[], sceneReferences: any[]): string {
    const characterRef = characterSheets.find(c => scene.characters?.includes(c.character));
    const sceneRef = sceneReferences.find(s => s.scene === scene.name);
    
    let prompt = `Create a cinematic ${scene.duration || 10}-second video of ${scene.description || scene.name}.`;
    
    if (sceneRef) {
      prompt += ` Setting: ${sceneRef.setting}. Mood: ${sceneRef.mood}.`;
    }
    
    if (characterRef) {
      prompt += ` Character: ${characterRef.description}.`;
    }
    
    if (scene.setting) {
      prompt += ` Environment: ${scene.setting}.`;
    }
    
    prompt += ' Style: Cinematic quality with professional lighting, smooth camera movements, and 16:9 aspect ratio. Focus on visual storytelling and emotional atmosphere.';
    
    return prompt;
  }

  private static generateMockVideoUrl(sceneName: string, thumbnailImage?: string): string {
    // Generate different sample videos based on scene content
    const videoPool = [
      'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4',
      'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ElephantsDream.mp4',
      'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerBlazes.mp4',
      'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerEscapes.mp4',
      'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerFun.mp4',
      'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerJoyrides.mp4',
      'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerMeltdowns.mp4',
      'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/Sintel.mp4'
    ];
    
    // Use scene name to consistently pick the same video for the same scene
    const sceneHash = sceneName.split('').reduce((hash, char) => {
      return ((hash << 5) - hash + char.charCodeAt(0)) & 0xffffffff;
    }, 0);
    
    const videoIndex = Math.abs(sceneHash) % videoPool.length;
    return videoPool[videoIndex];
  }

  private static findSceneReferenceImage(scene: any, sceneReferences: any[]): string | null {
    const reference = sceneReferences.find(ref => ref.scene === scene.name);
    return reference?.image || null;
  }

  // Mock data methods for demonstration
  private static getMockScreenplayData(): any[] {
    return [
      {
        type: 'parsed_screenplay',
        data: {
          title: 'Left Swipe',
          characters: [
            { name: 'MAYA', description: 'Young woman with long brown hair, quiet and sad expression, wearing oversized grey hoodie' },
            { name: 'KODEX', description: 'Sentient AI with sharp features, luminous holographic skin, minimalistic metallic suit' }
          ],
          scenes: [
            { name: 'INT. MAYA\'S FLAT - NIGHT', setting: 'Cozy but melancholic flat interior', mood: 'intimate, warm lighting', duration: 15 },
            { name: 'DIGITAL REALM', setting: 'Surreal futuristic space with glass floors', mood: 'surreal, dark blue and violet lighting', duration: 30 }
          ],
          dialogue: [
            { character: 'MAYA', text: 'He wasn\'t even cute enough to cry over.', scene: 'INT. MAYA\'S FLAT - NIGHT' },
            { character: 'KODEX', text: 'Their data... dissolved.', scene: 'DIGITAL REALM' }
          ]
        },
        timestamp: new Date().toISOString()
      },
      {
        type: 'extracted_data',
        characters: [
          { name: 'MAYA', description: 'Young woman with long brown hair, quiet and sad expression, wearing oversized grey hoodie' },
          { name: 'KODEX', description: 'Sentient AI with sharp features, luminous holographic skin, minimalistic metallic suit' }
        ],
        scenes: [
          { name: 'INT. MAYA\'S FLAT - NIGHT', setting: 'Cozy but melancholic flat interior', mood: 'intimate, warm lighting', duration: 15 },
          { name: 'DIGITAL REALM', setting: 'Surreal futuristic space with glass floors', mood: 'surreal, dark blue and violet lighting', duration: 30 }
        ],
        dialogue: [
          { character: 'MAYA', text: 'He wasn\'t even cute enough to cry over.', scene: 'INT. MAYA\'S FLAT - NIGHT' },
          { character: 'KODEX', text: 'Their data... dissolved.', scene: 'DIGITAL REALM' }
        ],
        timeline: []
      }
    ];
  }

  private static getMockCharacterSheets(): any[] {
    return [
      {
        type: 'character',
        character: 'MAYA',
        image: 'https://images.unsplash.com/photo-1494790108755-2616b612b786?w=800&q=80',
        description: 'Young woman with long brown hair, oversized grey hoodie, melancholic expression',
        timestamp: new Date().toISOString()
      },
      {
        type: 'scene',
        scene: 'INT. MAYA\'S FLAT',
        image: 'https://images.unsplash.com/photo-1586023492125-27b2c045efd7?w=400',
        setting: 'Cozy apartment interior',
        mood: 'intimate',
        timestamp: new Date().toISOString()
      }
    ];
  }

  private static getMockDialogueAudio(): any[] {
    return [
      {
        type: 'dialogue_audio',
        character: 'MAYA',
        text: 'He wasn\'t even cute enough to cry over.',
        audioUrl: 'data:audio/wav;base64,mock_audio_data',
        timestamp: new Date().toISOString()
      }
    ];
  }

  private static getMockVideoClips(): any[] {
    return [
      {
        type: 'video_clip',
        scene: 'INT. MAYA\'S FLAT - NIGHT',
        videoUrl: 'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4',
        prompt: 'Young woman sitting on floor eating ice cream in dimly lit apartment',
        videoDescription: 'Intimate scene of a young woman in her apartment, soft lighting creates a melancholic atmosphere',
        cameraInstructions: 'Slow push-in, handheld feel for authenticity',
        lighting: 'Warm, dim interior lighting with practical sources',
        duration: 15,
        thumbnailUrl: 'https://images.unsplash.com/photo-1586023492125-27b2c045efd7?w=800&q=80',
        generatedBy: 'Google Veo (Gemini)',
        timestamp: new Date().toISOString()
      },
      {
        type: 'video_clip',
        scene: 'DIGITAL REALM',
        videoUrl: 'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ElephantsDream.mp4',
        prompt: 'Surreal digital space with holographic AI character',
        videoDescription: 'Ethereal digital environment with flowing data streams and luminous AI presence',
        cameraInstructions: 'Floating camera movements, otherworldly perspective',
        lighting: 'Blue and violet digital lighting with particle effects',
        duration: 20,
        thumbnailUrl: 'https://images.unsplash.com/photo-1635070041078-e363dbe005cb?w=800&q=80',
        generatedBy: 'Google Veo (Gemini)',
        timestamp: new Date().toISOString()
      }
    ];
  }

  private static getMockProcessedVideos(): any[] {
    return [
      {
        type: 'processed_video',
        scene: 'INT. MAYA\'S FLAT - NIGHT',
        videoUrl: 'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4',
        effects: ['glitch', 'pixelation', 'color_distortion'],
        processedUrl: 'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4',
        duration: 15,
        generatedBy: 'Google Veo (Processed)',
        timestamp: new Date().toISOString()
      },
      {
        type: 'processed_video',
        scene: 'DIGITAL REALM',
        videoUrl: 'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ElephantsDream.mp4',
        effects: ['digital_artifacts', 'ethereal_glow'],
        processedUrl: 'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ElephantsDream.mp4',
        duration: 20,
        generatedBy: 'Google Veo (Processed)',
        timestamp: new Date().toISOString()
      }
    ];
  }

  private static getMockAssembledVideo(): any[] {
    return [
      {
        type: 'assembled_video',
        url: 'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/Sintel.mp4',
        totalDuration: 45,
        clips: [
          {
            url: 'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4',
            duration: 15,
            scene: 'INT. MAYA\'S FLAT - NIGHT'
          },
          {
            url: 'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ElephantsDream.mp4',
            duration: 20,
            scene: 'DIGITAL REALM'
          }
        ],
        generatedBy: 'ReelChemist Assembly Pipeline',
        timestamp: new Date().toISOString()
      }
    ];
  }
}